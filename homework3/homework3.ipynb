{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 3\n",
    "#### Gavin Martin \n",
    "#### March 30, 2020\n",
    "#### CS 344 \n",
    "\n",
    "\n",
    "##Problem 1: \n",
    "\n",
    "Entropy(WillWait) = -( P(yes) * log2(P(yes)) + (1 - P(yes)) * log2( 1 - P(yes)))\n",
    "                  = -( 6/12 * log2(6/12) + 6/12 * log2(6/12))\n",
    "                  = 1\n",
    "                  \n",
    "Remainder(Price) = ( 7/12 * B(3/7)  + 2/12 * B(2/2) + 3/12 * B(1/3) )\n",
    "                 = ( 7/12 * .9852 + 2/12 * 0 + 3/12 * .9182 )\n",
    "                 = .804266 bits of information\n",
    "                 \n",
    "Information Gain(Price) = Entropy(willWait) - Remainder(Price)\n",
    "                        = 1 - .804266\n",
    "                        = .1957335 bits of information \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## Problem 2: \n",
    "\n",
    "In class we talked about how it was impossible for early researchers to create an XOR gate with their input output \n",
    "perceptrons. This didn't work because they were only using neural networks at 1 layer deep which worked well for AND and \n",
    "OR, but it did not work for XOR because that required 2 layers. The problem came from the linearity of the single layered\n",
    "network result and you couldn't describe an XOR that way because its non-linear. \n",
    "\n",
    "To Fix this, you can create a multi-layered network at 2 levels deep which solves the issue at hand. If you have a \n",
    "Nand gate, an OR gate, and an AND gate, you can solve it, but that requires the 2 layers mentioned above.  Or requires > .5 \n",
    "because (0 + 1) and AND requires > 1.5 because (1 + 1) which forces it to be more than one layer deep. \n",
    "\n",
    "I created my own neural network for this below. (In Github Repo as XOR.jpg in this homework3 directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import dataset.\n",
    "import tensorflow\n",
    "from keras.datasets import boston_housing\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------- COLUMN LEGEND --------------------------------\n",
    "# 0 - Crime: crime per capita\n",
    "# 1 - Zoning: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "# 2 - Indus: Proportion of non-retail business acres per town\n",
    "# 3 - Chas: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "# 4 - Nitrogen_Oxide: Nitric oxide concentration (parts per 10 million)\n",
    "# 5 - Avgerage_Rooms: Average number of rooms per dwelling\n",
    "# 6 - Age: Proportion of owner-occupied units built prior to 1940\n",
    "# 7 - Distances: Weighted distances to five Boston employment centers\n",
    "# 8 - Radial: Index of accessibility to radial highways\n",
    "# 9 - Tax: Full-value property tax rate per $10,000\n",
    "# 10 - Pupil_Teacher: Pupil-teacher ratio by town\n",
    "# 11 - Black: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
    "# 12 - Low_Status: Percentage of lower status of the population\n",
    "# 13 - Median_Val: Median value of owner-occupied homes in $1000s\n",
    "\n",
    "\n",
    "# I Split it 20% validation data and 80% Training data given that it was 404 rows total\n",
    "validation_dataset = train_data[:82]\n",
    "train_dataset = train_data[82:]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Data Structure Dimensions: \")\n",
    "print(\"\\tTrain Data Dimensions: \" + str(train_dataset.ndim))\n",
    "print(\"\\tTrain Data Shape: \" + str(train_dataset.shape))\n",
    "print(\"\\tValidation Data Dimensions: \" + str(validation_dataset.ndim))\n",
    "print(\"\\tValidation Data Shape: \" + str(validation_dataset.shape))\n",
    "print(\"\\tTest Data Dimensions: \" + str(test_data.ndim))\n",
    "print(\"\\tTest Data Shape: \" + str(test_data.shape))\n",
    "\n",
    "\n",
    "validation_dataframe = pandas.DataFrame(validation_dataset)\n",
    "# Shuffles dataframe\n",
    "validation_dataframe = validation_dataframe.reindex(np.random.permutation(validation_dataframe.index))\n",
    "\n",
    "training_dataframe = pandas.DataFrame(train_dataset)\n",
    "# Shuffles dataframe\n",
    "training_dataframe = training_dataframe.reindex(np.random.permutation(training_dataframe.index))\n",
    "\n",
    "testing_dataframe = pandas.DataFrame(test_data)\n",
    "# Shuffles dataframe\n",
    "testing_dataframe = testing_dataframe.reindex(np.random.permutation(testing_dataframe.index))\n",
    "\n",
    "print(\"\\nValidation dataframe: \")\n",
    "print(validation_dataframe.describe())\n",
    "print(\"\\nTraining dataframe: \")\n",
    "print(training_dataframe.describe())\n",
    "print(\"\\nTesting dataframe: \")\n",
    "print(testing_dataframe.describe())\n",
    "\n",
    "# Synthentic Variable: I want to predict the median value of owner occupied homes Median_Val using\n",
    "#   (Tax / Crime Rate) because I believe the crime rate will have some effect on the median value of housing in the area\n",
    "#   A Decreasing value for tax/crime rate, should and likely would in my opinion indicate a decreasing median home value\n",
    "#\n",
    "#\n",
    "\n",
    "property_tax_crime_rate_train = training_dataframe[9] / training_dataframe[0]\n",
    "training_dataframe['property_tax_crime_rate'] = property_tax_crime_rate_train\n",
    "\n",
    "property_tax_crime_rate_validation = validation_dataframe[9] / validation_dataframe[0]\n",
    "validation_dataframe['property_tax_crime_rate'] = property_tax_crime_rate_validation\n",
    "\n",
    "property_tax_per_crime_rate_test = testing_dataframe[9] / testing_dataframe[0]\n",
    "testing_dataframe['property_tax_crime_rate'] = property_tax_per_crime_rate_test\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nValidation dataframe: \")\n",
    "print(validation_dataframe.describe())\n",
    "print(\"\\nTraining dataframe: \")\n",
    "print(training_dataframe.describe())\n",
    "print(\"\\nTesting dataframe: \")\n",
    "print(testing_dataframe.describe())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}