{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#Part 1: \n",
    "\n",
    "Neural Networks are very unlikely to become a bust like the expert systems and perceptions. With perceptions, they were \n",
    "unable to learn anything that wasn’t organized linearly like XOR.  This shortened the use case to linear problems which \n",
    "are rare in the real world. Expert systems require detailed tweaking and very detail-oriented design in regards to the \n",
    "extremely specific problems they were built for. Deep Learning is unlike both of those in the way that it is a problem \n",
    "method that generalizes really well to nearly all sorts of problems and by design, it is easy to make it work for any \n",
    "problem given to it. \n",
    "\n",
    "\n",
    "Deep learning also serves much more practical purposes than perceptions or deep learning. It allows us to do things\n",
    " that we could never explicitly program things to do, like playing GO since a game like GO has more moves than a computer \n",
    " would ever have time to estimate, even with a heuristic. It solves classification problems which are extremely useful in \n",
    " practical every field from business, medical, and recreational enjoyment. With deep learning, we don’t have to learn how \n",
    " to solve any problem, it just requires data to analyze, and it solves itself. To some degree, deep learning is like having\n",
    "  the answer book to programming problems in general, in that it creates the method to get the answers as long as you have \n",
    "  some of the answers to teach it with. \n",
    "  \n",
    "Another thing to consider with Deep Learning in comparison to past uses of AI is the infancy of this new discovery.\n",
    " Already in the beginning stages of deep learning with neural networks, we’re seeing progress and advancements that will \n",
    " prove useful everywhere for many decades to come, but we are improving every day. Even with Moore’s law slowing down, \n",
    " computers are becoming faster, and researching companies like Google and Microsoft are finding newer and more complex \n",
    " ways to implement AI to solve even greater tasks. Google is finding ways to automate the training process so AI models \n",
    " continuously train themselves to solve greater problems with smaller error rates. Deep learning will become more prominent \n",
    " in every field as we learn more from it and the proof for this is how useful its proven to be in its early stages of existence. \n",
    "\n",
    "\n",
    "\n",
    "#Part 2: \n",
    "\n",
    "Image attached in file homework4.jpeg\n",
    "\n",
    "\n",
    "#Part 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 121,930\n",
      "Trainable params: 121,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.5101 - accuracy: 0.8120\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.3281 - accuracy: 0.8794\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2784 - accuracy: 0.8993\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2470 - accuracy: 0.9095\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2236 - accuracy: 0.9183\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2048 - accuracy: 0.9252\n",
      "10000/10000 [==============================] - 6s 556us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2674380237877369, 0.9059000015258789]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=6, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I tried it with 2-3 layers, and 2 layers with 6 epochs, and a batch size of 64 worked better for me than anything else \n",
    "at 92.74%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
