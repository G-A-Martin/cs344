
Question 1:

What does the Pearson correlation coefficient measure? Identify one example value from the correlation table you compute
and explain why it makes sense.

- Pearson Correlation Coefficients measures the linear correlation between to variables, like to features or a feature and
a target. It is measured as -1 for perfect negative correlation, 0 for no correlation, and 1 for perfect positive correlation.

- Population and total rooms have a correlation of .9 which makes sense because a higher population usually means more
rooms on a single block.

Question 2:

Submit your solutions to tasks 1â€“2. Include the features you selected for task 1 and the synthetic features you developed
for task 2; include the final RMS errors but not the training output. Did you beat the Google-provided baselines?


Task 1

My code:

My features = rooms_per_person and median_income

minimal_features = [
    "rooms_per_person",
    "median_income"
]

assert minimal_features, "You must select at least one feature!"

minimal_training_examples = training_examples[minimal_features]
minimal_validation_examples = validation_examples[minimal_features]

#
# Don't forget to adjust these parameters.
#
train_model(
    learning_rate=0.1,
    steps=500,
    batch_size=5,
    training_examples=minimal_training_examples,
    training_targets=training_targets,
    validation_examples=minimal_validation_examples,
    validation_targets=validation_targets)

Output:

Training model...
RMSE (on training data):
  period 00 : 132.50
  period 01 : 85.74
  period 02 : 85.05
  period 03 : 84.22
  period 04 : 84.33
  period 05 : 84.57
  period 06 : 84.24
  period 07 : 84.09
  period 08 : 84.13
  period 09 : 84.09
Model training finished.


Mine did better than Google. Google's was at 113.07 while mine was 84.09 RSME



Task 2

def select_and_transform_features(source_df):
  LATITUDE_RANGES = zip(range(32, 44), range(33, 45))
  selected_examples = pd.DataFrame()
  selected_examples["median_income"] = source_df["median_income"]
  for r in LATITUDE_RANGES:
    selected_examples["latitude_%d_to_%d" % r] = source_df["latitude"].apply(
      lambda l: 1.0 if l >= r[0] and l < r[1] else 0.0)
  return selected_examples

selected_training_examples = select_and_transform_features(training_examples)
selected_validation_examples = select_and_transform_features(validation_examples)

_ = train_model(
    learning_rate=0.1,
    steps=500,
    batch_size=5,
    training_examples=selected_training_examples,
    training_targets=training_targets,
    validation_examples=selected_validation_examples,
    validation_targets=validation_targets)

Training model...
RMSE (on training data):
  period 00 : 140.69
  period 01 : 86.81
  period 02 : 84.31
  period 03 : 83.85
  period 04 : 83.43
  period 05 : 83.19
  period 06 : 82.83
  period 07 : 82.51
  period 08 : 82.73
  period 09 : 82.22
Model training finished.

This was better than Google's at 140.54 RMSE